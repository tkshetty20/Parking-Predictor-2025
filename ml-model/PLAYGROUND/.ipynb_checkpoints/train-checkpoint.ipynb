{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f601fb-fc7e-4d2a-94f8-a5270823f0db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model using TimeSeriesSplit for time-based validation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Import the necessary libraries\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Fit the model using TimeSeriesSplit for time-based validation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import joblib\n",
    "\n",
    "model_data_directory = 'model_data'\n",
    "if not os.path.exists(model_data_directory):\n",
    "    os.makedirs(model_data_directory)\n",
    "\n",
    "scaler_data_directory = 'scaler_data'\n",
    "if not os.path.exists(scaler_data_directory):\n",
    "    os.makedirs(scaler_data_directory)\n",
    "\n",
    "def save_model(model, filename):\n",
    "    \"\"\"\n",
    "    Save the trained model to a file in the model_data subdirectory.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained Keras model\n",
    "    - filename: The name of the file where the model will be saved\n",
    "    \"\"\"\n",
    "    full_path = os.path.join(model_data_directory, filename)\n",
    "    model.save(full_path)\n",
    "    print(f\"Model saved to {full_path}\")\n",
    "\n",
    "\n",
    "def preprocess_data(df, target_column, scaler, sequence_length=5, forecast_horizon=6, step_size=5):\n",
    "    \"\"\"\n",
    "    Preprocess the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the 'ts' and target_column columns\n",
    "    - target_column: the name of the target column in the DataFrame\n",
    "    - scaler: an instance of sklearn's MinMaxScaler or similar\n",
    "    - sequence_length: the number of previous time steps to use as input features\n",
    "    - forecast_horizon: the number of future time steps to predict\n",
    "\n",
    "    Returns:\n",
    "    - X: The input features for the LSTM model\n",
    "    - y: The target variables for the LSTM model\n",
    "    \"\"\"\n",
    "    # Convert timestamps to pandas datetime\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "\n",
    "    # Extract day of the week and time of the day as features\n",
    "    df['day_of_week'] = df['ts'].dt.dayofweek\n",
    "    df['time_of_day'] = df['ts'].dt.hour + df['ts'].dt.minute / 60\n",
    "\n",
    "    # Scale the target column\n",
    "    df[target_column] = scaler.fit_transform(df[[target_column]])\n",
    "\n",
    "    # Initialize X and y\n",
    "    X, y = [], []\n",
    "\n",
    "    # Flag to check if first sequence has been printed\n",
    "    first_sequence_printed = False\n",
    "\n",
    "    # Create sequences of past observations as input features and future values as targets\n",
    "    for i in range(sequence_length, len(df) - (forecast_horizon*step_size), step_size):\n",
    "        sequence = df[[target_column, 'day_of_week', 'time_of_day']].iloc[i-sequence_length:i].values\n",
    "        target_values = df[target_column].iloc[i:i + (forecast_horizon * step_size):step_size].values\n",
    "        X.append(sequence)\n",
    "        y.append(target_values)\n",
    "\n",
    "        # Enhanced print statement for the first sequence\n",
    "        if not first_sequence_printed:\n",
    "            print(\"Example of a single sequence in X and corresponding future values in y:\")\n",
    "            print(\"X Sequence (Input features):\")\n",
    "            print(sequence)\n",
    "            print(\"y Values (Future target values):\")\n",
    "            print(target_values)\n",
    "            first_sequence_printed = True  # Update the flag\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# File paths and corresponding target column names\n",
    "file_info = {\n",
    "    'data/Sign1_full_fitted.csv': 'y1',\n",
    "    'data/Sign12_full_fitted.csv': 'y12',\n",
    "    'data/Sign14_full_fitted.csv': 'y14'\n",
    "}\n",
    "\n",
    "for file_name, target_column in file_info.items():\n",
    "    print(\"Loading data...\")\n",
    "    data = pd.read_csv(file_name)\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # Initialize the scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    print(\"Scaler initialized.\")\n",
    "\n",
    "    # Preprocess the data\n",
    "    print(\"Preprocessing data...\")\n",
    "    X, y = preprocess_data(data, target_column, scaler)\n",
    "    print(\"Data preprocessing complete.\")\n",
    "\n",
    "    # Output the shapes of our inputs and outputs\n",
    "    print(f\"Shape of input features (X): {X.shape}\")\n",
    "    print(f\"Shape of target (y): {y.shape}\")\n",
    "\n",
    "    forecast_horizon = 6\n",
    "\n",
    "    # Define the LSTM model\n",
    "    print(\"Defining the LSTM model...\")\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', input_shape=(X.shape[1], X.shape[2])),\n",
    "        Dense(forecast_horizon)\n",
    "    ])\n",
    "    print(\"Model defined.\")\n",
    "\n",
    "    # Compile the model\n",
    "    print(\"Compiling the model...\")\n",
    "    model.compile(optimizer='adam', loss='mean_absolute_error')\n",
    "    print(\"Model compiled.\")\n",
    "\n",
    "    # Define callbacks\n",
    "    print(\"Defining callbacks...\")\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    model_checkpoint = ModelCheckpoint('best_model_'+file_name+'.h5', save_best_only=True)\n",
    "    print(\"Callbacks defined.\")\n",
    "\n",
    "    print(\"Starting model training with TimeSeriesSplit...\")\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        print(f\"Training fold...\")\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=100, validation_data=(\n",
    "            X_test, y_test), callbacks=[early_stopping, model_checkpoint])\n",
    "        print(f\"Fold training completed.\")\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Plot predictions vs actual values with different colors\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(y_test, label='Actual Values', color='blue')  # Actual values in blue\n",
    "        plt.plot(predictions, label='Predicted Values', color='orange')  # Predicted values in orange\n",
    "        plt.title('Model Predictions vs Actual Values')\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Target Variable')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    model_filename = f'model_{target_column}.h5'  # You can modify the naming convention as needed\n",
    "    save_model(model, model_filename)\n",
    "\n",
    "    scaler_filename = f'scaler_{target_column}.joblib'\n",
    "    scaler_path = os.path.join(scaler_data_directory, scaler_filename)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    print(f\"Scaler saved to {scaler_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf9ef7-3919-4c5a-b1aa-04fdd23fee2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
